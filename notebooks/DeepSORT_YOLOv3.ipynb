{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSORT_YOLOv3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMjmfT5bZb6",
        "colab_type": "text"
      },
      "source": [
        "# Pedestrian Tracking with YOLOv3 and DeepSORT\n",
        "\n",
        "This is a pedestrian tracking demo using the open source project [ZQPei/deep_sort_pytorch](https://github.com/ZQPei/deep_sort_pytorch) which combines [DeepSORT](https://github.com/nwojke/deep_sort) with [YOLOv3](https://pjreddie.com/darknet/yolo/).\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "## Install ZQPei/deep_sort_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-swJb8AnUwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "project_name = \"deep_sort_pytorch\"\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive https://github.com/ZQPei/deep_sort_pytorch.git\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "sys.path.append(join(project_name, 'YOLOv3'))\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uPYXRG3RQ8e",
        "colab_type": "text"
      },
      "source": [
        "## Download pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h15jd8tyoANM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not exists('yolov3.weights'):\n",
        "  !wget -q https://pjreddie.com/media/files/yolov3.weights\n",
        "    \n",
        "if not exists('ckpt.t7'):\n",
        "  file_id = '1_qwTWdzT9dWNudpusgKavj_4elGgbkUN'\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&id={file_id}\" -o ckpt.t7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBsW63L4Rw1U",
        "colab_type": "text"
      },
      "source": [
        "## Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_YpTfFwSCC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "\n",
        "from YOLOv3 import YOLOv3\n",
        "from deep_sort import DeepSort\n",
        "from util import draw_bboxes\n",
        "\n",
        "yolo3 = YOLOv3(\"deep_sort_pytorch/YOLOv3/cfg/yolo_v3.cfg\",\"yolov3.weights\",\"deep_sort_pytorch/YOLOv3/cfg/coco.names\", is_xywh=True)\n",
        "deepsort = DeepSort(\"ckpt.t7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-OHRN2qSMnN",
        "colab_type": "text"
      },
      "source": [
        "## Track pedestrians\n",
        "\n",
        "First, download a test video from internet and show in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHS89UbJoNfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VIDEO_URL = 'http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentreXVID.avi'\n",
        "DURATION_S = 20  # process only the first 20 seconds\n",
        "\n",
        "\n",
        "\n",
        "video_file_name = 'video.mp4'\n",
        "if not exists(video_file_name):\n",
        "  !wget -q $VIDEO_URL\n",
        "  dowloaded_file_name = basename(VIDEO_URL)\n",
        "  # convert to MP4, because we can show only MP4 videos in the colab noteook\n",
        "  !ffmpeg -y -loglevel info -t $DURATION_S -i $dowloaded_file_name $video_file_name\n",
        "  \n",
        "\n",
        "def show_local_mp4_video(file_name, width=640, height=480):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
        " \n",
        "clear_output()\n",
        "video = show_local_mp4_video('video.mp4')\n",
        "video"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUmYyIrqSl1D",
        "colab_type": "text"
      },
      "source": [
        "Now, track the pedestrians on the downloaded video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-j5tW6-PxSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_capture = cv2.VideoCapture()\n",
        "if video_capture.open('video.mp4'):\n",
        "  width, height = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "  !rm -f output.mp4 output.avi\n",
        "  # can't write out mp4, so try to write into an AVI file\n",
        "  video_writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
        "  while video_capture.isOpened():\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "      break\n",
        "      \n",
        "    start = time.time()\n",
        "    xmin, ymin, xmax, ymax = 0, 0, width, height\n",
        "    im = frame[ymin:ymax, xmin:xmax, (2,1,0)]\n",
        "    bbox_xywh, cls_conf, cls_ids = yolo3(im)\n",
        "    if bbox_xywh is not None:\n",
        "        mask = cls_ids==0\n",
        "        bbox_xywh = bbox_xywh[mask]\n",
        "        bbox_xywh[:,3] *= 1.2\n",
        "        cls_conf = cls_conf[mask]\n",
        "        outputs = deepsort.update(bbox_xywh, cls_conf, im)\n",
        "        if len(outputs) > 0:\n",
        "            bbox_xyxy = outputs[:,:4]\n",
        "            identities = outputs[:,-1]\n",
        "            frame = draw_bboxes(frame, bbox_xyxy, identities, offset=(xmin,ymin))\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"time: {}s, fps: {}\".format(end-start, 1/(end-start)))\n",
        "            \n",
        "    video_writer.write(frame)\n",
        "  video_capture.release()\n",
        "  video_writer.release()\n",
        "  \n",
        "  # convert AVI to MP4\n",
        "  !ffmpeg -y -loglevel info -i output.avi output.mp4\n",
        "else:\n",
        "  print(\"can't open the given input video file!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il1RKuhOSxCG",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can visualize the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG2UQsD7aAgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_local_mp4_video('output.mp4', width=960, height=720)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}